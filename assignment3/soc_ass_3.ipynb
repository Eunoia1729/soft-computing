{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "soc_ass_3.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAaEMR7oBLPO"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0phu_DBFoQRn"
      },
      "source": [
        "Note : Pandas library is only used for data cleaning. All implementations are done using only numpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-153jveBHgv"
      },
      "source": [
        "class LinearRegression:\n",
        "  W = None\n",
        "  lamba = None\n",
        "  L = None\n",
        "\n",
        "  def __init__(self, n_features, lamda = 0):\n",
        "    self.L = np.identity(n_features + 1)\n",
        "    self.L[0][0] = 0\n",
        "    self.lamda = lamda\n",
        "\n",
        "  def fit(self, X_old, Y):\n",
        "    X = np.copy(X_old)\n",
        "    bias = np.ones((X.shape[0], 1))\n",
        "    X = np.hstack(( bias, X))\n",
        "\n",
        "    # (X.T X + lambda.L)^-1 . X.T Y\n",
        "    A = np.matmul(X.T, X) + self.lamda*self.L\n",
        "    B = np.matmul(X.T, Y)\n",
        "    self.W = (np.linalg.solve(A, B))\n",
        "    return self.W\n",
        "\n",
        "  def predict(self, X_old):\n",
        "    X = np.copy(X_old)\n",
        "    bias = np.ones((X.shape[0], 1))\n",
        "    X = np.hstack(( bias, X))\n",
        "    \n",
        "    return np.matmul(X, self.W)\n",
        "\n",
        "  def predictionError(self, X, Y):\n",
        "    prediction_error = np.mean(np.abs((Y - self.predict(X))/Y))\n",
        "    return f\"{round(prediction_error * 100, 2)}%\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnuk4TxjsI1x"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icuz8y1-BM9J"
      },
      "source": [
        "df = pd.read_csv('housing_price_dataset.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeHZB0fNl3Oc"
      },
      "source": [
        "df = df.rename(columns={\"lotsize\": \"plotsize\",\"bedrooms\":\"n_bedrooms\",\"bathrms\":\"n_bathrooms\"})\n",
        "df = df[ ['plotsize','n_bedrooms','n_bathrooms','price']]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9M-pi_v_CWqm",
        "outputId": "f37ca708-8b40-48c4-fbe3-c21cea764709"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>plotsize</th>\n",
              "      <th>n_bedrooms</th>\n",
              "      <th>n_bathrooms</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5850</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>42000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4000</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>38500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3060</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>49500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6650</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>60500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6360</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>61000.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   plotsize  n_bedrooms  n_bathrooms    price\n",
              "0      5850           3            1  42000.0\n",
              "1      4000           2            1  38500.0\n",
              "2      3060           3            1  49500.0\n",
              "3      6650           3            1  60500.0\n",
              "4      6360           2            1  61000.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilatN6dkCXhW",
        "outputId": "b975b470-cb92-44ed-8647-fe7742bee6c3"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "546"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAtcxHn1CbAZ"
      },
      "source": [
        "train_size = 0.75\n",
        "N = len(df)\n",
        "\n",
        "data_np = df.to_numpy(dtype=np.float64)\n",
        "np.random.seed(42) \n",
        "np.random.shuffle(data_np)\n",
        "train, test = data_np[: int(N*train_size),:], data_np[ int(N*train_size):,:]"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFLKIefXEL0T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f1cfd24-b080-485a-ecd4-b7a4f0fc9d1d"
      },
      "source": [
        "X_train, Y_train = train[:,0:3], train[:,3:4] \n",
        "X_test, Y_test = test[:,0:3], test[:,3:4] \n",
        "\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(409, 3)\n",
            "(409, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT7BIDdBtjGw"
      },
      "source": [
        "n_features = X_train.shape[1]\n",
        "n_samples = X_train.shape[0]"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLFyD8bzE4on"
      },
      "source": [
        "## Without regularization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZpwcfknnNQ3",
        "outputId": "71f10439-3394-4eb4-d83b-00411889dcf1"
      },
      "source": [
        "print('Without Regularization:')\n",
        "lr_without_reg = LinearRegression(n_features = n_features)\n",
        "lr_without_reg.fit(X_train, Y_train)\n",
        "print(f'Prediction Error : {lr_without_reg.predictionError(X_test, Y_test)} ')"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Without Regularization:\n",
            "Prediction Error : 21.96% \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEKCKJukE9H4"
      },
      "source": [
        "## With Regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOEQTbVkEH5j",
        "outputId": "6e4295fe-f922-4ded-a1e6-4d1723aacd7c"
      },
      "source": [
        "# lamda_list = np.arange(0, 500, 10)\n",
        "lamda_list = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 100, 1000, 10000, 10000000]\n",
        "print('With Regularization:')\n",
        "  \n",
        "for lamda in lamda_list:\n",
        "  lr_with_reg = LinearRegression(n_features = n_features, lamda = lamda)\n",
        "  lr_with_reg.fit(X_train, Y_train)\n",
        "  print(f'Prediction Error with lamda = {lamda} : {lr_with_reg.predictionError(X_test, Y_test)}')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With Regularization:\n",
            "Prediction Error with lamda = 0 : 21.96%\n",
            "Prediction Error with lamda = 1 : 21.95%\n",
            "Prediction Error with lamda = 2 : 21.95%\n",
            "Prediction Error with lamda = 3 : 21.95%\n",
            "Prediction Error with lamda = 4 : 21.95%\n",
            "Prediction Error with lamda = 5 : 21.95%\n",
            "Prediction Error with lamda = 6 : 21.94%\n",
            "Prediction Error with lamda = 7 : 21.94%\n",
            "Prediction Error with lamda = 8 : 21.94%\n",
            "Prediction Error with lamda = 9 : 21.94%\n",
            "Prediction Error with lamda = 10 : 21.94%\n",
            "Prediction Error with lamda = 100 : 22.34%\n",
            "Prediction Error with lamda = 1000 : 24.45%\n",
            "Prediction Error with lamda = 10000 : 25.49%\n",
            "Prediction Error with lamda = 10000000 : 25.68%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdX9Fojl391L"
      },
      "source": [
        "def feature_scale(a):\n",
        "  return (a - np.mean(a)) / np.std(a)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjDyJhLfEVRk"
      },
      "source": [
        "import random\n",
        "class LinearRegressionWithGDA:\n",
        "  W = None\n",
        "  alpha = None\n",
        "\n",
        "  def __init__(self, n_features, lamda = 0, alpha = 0.01):\n",
        "    self.L = np.identity(n_features + 1)\n",
        "    self.L[0][0] = 0\n",
        "    self.lamda = lamda\n",
        "    self.alpha = alpha\n",
        "    self.W = np.zeros((n_features + 1, 1))\n",
        "    self.n_features = n_features\n",
        "\n",
        "  def trainWithSGD(self, samples, n_epochs = 5):\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "      np.random.shuffle(samples)\n",
        "      for sample in samples:\n",
        "        dW = self.calculateLoss(np.array([sample]))\n",
        "        self.W = self.W - self.alpha*dW\n",
        "    \n",
        "    return self.W\n",
        "\n",
        "  def trainWithMBGD(self, D, batch_size, n_epochs = 5):\n",
        "\n",
        "    for _ in range(n_epochs):\n",
        "      batch = D[np.random.choice(D.shape[0], 2, replace=False), :]\n",
        "      # a[np.random.choice(len(a))]\n",
        "      dW = self.calculateLoss(np.array(batch))\n",
        "      self.W = self.W - self.alpha*dW\n",
        "\n",
        "  def calculateLoss(self, D):\n",
        "    X_old, Y = D[:, 0: self.n_features], D[:, self.n_features:]\n",
        "    X = np.copy(X_old)\n",
        "    bias = np.ones((X.shape[0], 1))\n",
        "    X = np.hstack(( bias, X))\n",
        "\n",
        "    L = np.ones(self.W.shape)\n",
        "    L[0][0] = 0\n",
        "    return (np.matmul( X.T, self.predict(X) - Y) + np.multiply(self.lamda*L, self.W))/ len(D)\n",
        "\n",
        "  def predict(self, X):\n",
        "    # print(X.shape, self.W.shape)\n",
        "    return np.matmul(X, self.W)\n",
        "\n",
        "  def predictionError(self, D):\n",
        "    X_old, Y = D[:, 0: self.n_features], D[:, self.n_features:]\n",
        "    X = np.copy(X_old)\n",
        "    bias = np.ones((X.shape[0], 1))\n",
        "    X = np.hstack(( bias, X))\n",
        "    prediction_error = np.mean(np.square((Y - self.predict(X)))) / 2\n",
        "    return f\"{round(prediction_error, 2)}\"\n",
        "\n",
        "  def predictionErrorp(self, D):\n",
        "    X_old, Y = D[:, 0: self.n_features], D[:, self.n_features:]\n",
        "    X = np.copy(X_old)\n",
        "    bias = np.ones((X.shape[0], 1))\n",
        "    X = np.hstack(( bias, X))\n",
        "    prediction_error = np.mean(np.abs((Y - self.predict(X))/Y))\n",
        "    return f\"{round(prediction_error, 2)}%\""
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QsbCwvCFC9C"
      },
      "source": [
        "## Stochastic, batch and mini batch without scaling and without regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCO5O5E0DkmU",
        "outputId": "019f63d0-468e-4e18-d92b-5ddc096d1756"
      },
      "source": [
        "print('With Batch Stochastic:')\n",
        "lr_with_MBGD = LinearRegressionWithGDA(n_features=n_features)\n",
        "W = lr_with_MBGD.trainWithMBGD(train, batch_size = n_samples)\n",
        "print(f'Prediction Error : {lr_with_MBGD.predictionError(test)} ')\n"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With Batch Stochastic:\n",
            "Prediction Error : 1.5659815289266656e+63 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqQUrBEpDvc0",
        "outputId": "48b4e46a-f327-4f68-9b24-3a36bab6f363"
      },
      "source": [
        "print('With Mini Batch Stochastic:')\n",
        "lr_with_MBGD = LinearRegressionWithGDA(n_features=n_features)\n",
        "W = lr_with_MBGD.trainWithMBGD(train, batch_size = 32)\n",
        "print(f'Prediction Error : {lr_with_MBGD.predictionError(test)} ')\n"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With Mini Batch Stochastic:\n",
            "Prediction Error : 1.1966370948548148e+63 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwjrjQevDrqC",
        "outputId": "d36583d0-fa0c-49d6-ec8a-34adf1d80389"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print('With Stochastic:')\n",
        "lr_with_SGD = LinearRegressionWithGDA(n_features=n_features)\n",
        "W = lr_with_SGD.trainWithSGD(train)\n",
        "print(f'Prediction Error : {lr_with_MBGD.predictionError(test)} ')\n"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With Stochastic:\n",
            "Prediction Error : 1.1966370948548148e+63 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeQcmu2f4Bil"
      },
      "source": [
        "from sklearn.preprocessing import normalize\n",
        "def feature_scale_dataset(D):\n",
        "  return (D- np.min( D, axis = 0)) / ( np.max(D,axis=0) - np.min(D,axis=0))"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9bZAIYGFMQp"
      },
      "source": [
        "## Stochastic, batch and mini batch with scaling and without regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fq1viZq39_cC",
        "outputId": "fb1e35b8-250b-4228-84a1-1e4e1fef0d76"
      },
      "source": [
        "train_scaled = feature_scale_dataset(train)\n",
        "test_scaled = feature_scale_dataset(test)\n",
        "X_train_scaled, Y_train_scaled = train_scaled[:,0:3], train_scaled[:,3:4] \n",
        "X_test_scaled, Y_test_scaled = test_scaled[:,0:3], test_scaled[:,3:4] \n",
        "print(train_scaled)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.35821306 0.4        0.         0.26666667]\n",
            " [0.14639175 0.2        0.         0.18484848]\n",
            " [0.10103093 0.4        0.         0.15151515]\n",
            " ...\n",
            " [0.08659794 0.2        0.         0.07393939]\n",
            " [0.19587629 0.6        0.33333333 0.15757576]\n",
            " [0.18570447 0.6        0.         0.10606061]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMK2cWX53SrS",
        "outputId": "903c5067-8356-4ddb-e8fe-ba8164729d54"
      },
      "source": [
        "print('With feature scaling:')\n",
        "\n",
        "print('With Stochastic:')\n",
        "lr_with_SGD_scaled = LinearRegressionWithGDA(n_features=n_features)\n",
        "W = lr_with_SGD_scaled.trainWithSGD(train_scaled, n_epochs = 200)\n",
        "print(f'Prediction Error : {lr_with_SGD_scaled.predictionError(test_scaled)} ')\n"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With feature scaling:\n",
            "With Stochastic:\n",
            "[[0.03639746]\n",
            " [0.47049228]\n",
            " [0.19383367]\n",
            " [0.3564152 ]]\n",
            "Prediction Error : 0.01 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfpdNgfF_tgE",
        "outputId": "01f0c9a2-1a44-4eb5-ca07-ef39c4a23d2a"
      },
      "source": [
        "print('With Batch Gradient:')\n",
        "lr_with_BGD_scaled = LinearRegressionWithGDA(n_features=n_features)\n",
        "W = lr_with_BGD_scaled.trainWithMBGD(train_scaled, n_epochs = 100, batch_size = n_samples)\n",
        "print(f'Prediction Error : {lr_with_BGD_scaled.predictionError(test_scaled)} ')\n"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With Batch Gradient:\n",
            "Prediction Error : 0.02 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lCytYABDBn3",
        "outputId": "292b61d6-54e7-49b1-d8e8-9c3a680c6acb"
      },
      "source": [
        "print('With Mini Gradient:')\n",
        "batch_sizes = [2, 4, 8, 16, 32]\n",
        "for batch_size in batch_sizes:\n",
        "  lr_with_BGD_scaled = LinearRegressionWithGDA(n_features=n_features)\n",
        "  W = lr_with_BGD_scaled.trainWithMBGD(train_scaled, n_epochs = 100, batch_size = batch_size)\n",
        "  print(f'Prediction Error with batch size = {batch_size}: {lr_with_BGD_scaled.predictionError(test_scaled)} ')\n"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With Mini Gradient:\n",
            "Prediction Error with batch size = 2: 0.02 \n",
            "Prediction Error with batch size = 4: 0.02 \n",
            "Prediction Error with batch size = 8: 0.02 \n",
            "Prediction Error with batch size = 16: 0.02 \n",
            "Prediction Error with batch size = 32: 0.02 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hS-OyUAtFO6-"
      },
      "source": [
        "## Stochastic, batch and mini batch with scaling and with regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thus-uU4FYCX",
        "outputId": "cc8b4009-4452-4525-f5db-7339bd1f0f9f"
      },
      "source": [
        "print('With feature scaling:')\n",
        "\n",
        "print('With Stochastic:')\n",
        "lr_with_SGD_scaled = LinearRegressionWithGDA(n_features=n_features, lamda = 20)\n",
        "W = lr_with_SGD_scaled.trainWithSGD(train_scaled, n_epochs = 200)\n",
        "print(f'Prediction Error : {lr_with_SGD_scaled.predictionError(test_scaled)} ')\n"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With feature scaling:\n",
            "With Stochastic:\n",
            "Prediction Error : 0.02 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xs9_qaY1FYCZ",
        "outputId": "37bac751-92b5-42f2-fbd3-b620b8f88e47"
      },
      "source": [
        "print('With Batch Gradient:')\n",
        "lr_with_BGD_scaled = LinearRegressionWithGDA(n_features=n_features, lamda = 20)\n",
        "W = lr_with_BGD_scaled.trainWithMBGD(train_scaled, n_epochs = 100, batch_size = n_samples)\n",
        "print(f'Prediction Error : {lr_with_BGD_scaled.predictionError(test_scaled)} ')\n"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With Batch Gradient:\n",
            "Prediction Error : 0.03 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bh6Ku0LeFYCa",
        "outputId": "0dfa320f-c27c-4500-cca0-11d5ff9b9d39"
      },
      "source": [
        "print('With Mini Gradient:')\n",
        "batch_sizes = [2, 4, 8, 16, 32]\n",
        "for batch_size in batch_sizes:\n",
        "  lr_with_BGD_scaled = LinearRegressionWithGDA(n_features=n_features, lamda = 20)\n",
        "  W = lr_with_BGD_scaled.trainWithMBGD(train_scaled, n_epochs = 100, batch_size = batch_size)\n",
        "  print(f'Prediction Error with batch size = {batch_size}: {lr_with_BGD_scaled.predictionError(test_scaled)} ')\n"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With Mini Gradient:\n",
            "Prediction Error with batch size = 2: 0.03 \n",
            "Prediction Error with batch size = 4: 0.03 \n",
            "Prediction Error with batch size = 8: 0.02 \n",
            "Prediction Error with batch size = 16: 0.02 \n",
            "Prediction Error with batch size = 32: 0.02 \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}